{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92acf2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae31d93a038149728e3e16b305a08498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bcc883575d4652b2313cba17446e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Books reviews dataset\n",
    "dataset = load_dataset(\"cogsci13/Amazon-Reviews-2023-Books-Review\", \"default\", trust_remote_code=True)\n",
    "\n",
    "# Extract relevant fields\n",
    "df = pd.DataFrame({\n",
    "    'user_id': dataset['full']['user_id'],\n",
    "    'item_id': dataset['full']['parent_asin'],\n",
    "    'rating': dataset['full']['rating'],\n",
    "    'timestamp': dataset['full']['timestamp']\n",
    "})\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df_sorted = df.sort_values(by=['user_id', 'timestamp'])\n",
    "test_df = df_sorted.groupby('user_id').tail(2)\n",
    "train_df = df_sorted.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503ab2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a15f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "    #     self._init_weights()\n",
    "\n",
    "    # def _init_weights(self):\n",
    "    #     nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "    #     nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_vecs = self.user_embedding(user_indices)\n",
    "        item_vecs = self.item_embedding(item_indices)\n",
    "        scores = torch.sum(user_vecs * item_vecs, dim=1)\n",
    "        return torch.sigmoid(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ccf303",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ee95e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_{\\text{MSE}} = \\sum_{(u,i)} \\mathbf{1}_{ui} \\left( \\frac{r_{ui} - 1}{R_{\\max} - 1} - \\sigma(\\mathbf{p}_u \\cdot \\mathbf{q}_i) \\right)^2 + \\lambda_U \\sum_u \\|\\mathbf{p}_u\\|^2 + \\lambda_I \\sum_i \\|\\mathbf{q}_i\\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(model, user_indices, item_indices, ratings, lambda_reg=1e-4, r_max=5):\n",
    "    preds = model(user_indices, item_indices)\n",
    "    ratings_norm = (ratings - 1) / (r_max - 1)\n",
    "    mse = F.mse_loss(preds, ratings_norm)\n",
    "    reg_term = lambda_reg * (model.user_embedding.weight.norm(2).pow(2) + model.item_embedding.weight.norm(2).pow(2))\n",
    "    return mse + reg_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef0944",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_{\\text{BPR}} = \\sum_{(u,i,j)} \\ln \\sigma(\\mathbf{p}_u \\cdot \\mathbf{q}_i - \\mathbf{p}_u \\cdot \\mathbf{q}_j) - \\lambda \\|\\Theta\\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ed8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(model, user_indices, pos_item_indices, neg_item_indices, lambda_reg=1e-4):\n",
    "    user_vecs = model.user_embedding(user_indices)\n",
    "    pos_item_vecs = model.item_embedding(pos_item_indices)\n",
    "    neg_item_vecs = model.item_embedding(neg_item_indices)\n",
    "    pos_scores = torch.sum(user_vecs * pos_item_vecs, dim=1)\n",
    "    neg_scores = torch.sum(user_vecs * neg_item_vecs, dim=1)\n",
    "    loss = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores)))\n",
    "    reg_term = lambda_reg * (user_vecs.norm(2).pow(2) + pos_item_vecs.norm(2).pow(2) + neg_item_vecs.norm(2).pow(2))\n",
    "    return loss + reg_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc00583",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_{\\text{AU}} = \\mathbb{E}_{(u,i)} \\|\\mathbf{p}_u - \\mathbf{q}_i\\|^2 + \\lambda \\left( \n",
    "\\log \\mathbb{E}_{(u,v)} e^{-\\frac{1}{2}\\|\\mathbf{p}_u - \\mathbf{p}_v\\|^2} + \n",
    "\\log \\mathbb{E}_{(i,j)} e^{-\\frac{1}{2}\\|\\mathbf{q}_i - \\mathbf{q}_j\\|^2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c74741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment_uniformity_loss(model, user_item_pairs, lambda_reg=1e-2):\n",
    "    user_vecs = model.user_embedding(user_item_pairs[:, 0])\n",
    "    item_vecs = model.item_embedding(user_item_pairs[:, 1])\n",
    "    \n",
    "    alignment = torch.mean((user_vecs - item_vecs).pow(2).sum(dim=1))\n",
    "\n",
    "    user_norms = torch.cdist(model.user_embedding.weight, model.user_embedding.weight, p=2).pow(2)\n",
    "    item_norms = torch.cdist(model.item_embedding.weight, model.item_embedding.weight, p=2).pow(2)\n",
    "\n",
    "    uniformity_user = torch.log(torch.exp(-0.5 * user_norms).mean())\n",
    "    uniformity_item = torch.log(torch.exp(-0.5 * item_norms).mean())\n",
    "\n",
    "    return alignment + lambda_reg * (uniformity_user + uniformity_item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
