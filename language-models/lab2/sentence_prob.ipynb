{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd5d3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prych/.local/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "\n",
    "model_name = 'flax-community/papuGaPT2'\n",
    "device = 'cuda'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff22175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118.675048828125\n"
     ]
    }
   ],
   "source": [
    "print(model.num_parameters() / 1024 / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ccb512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ta', ' wie', 'wi', 'órka', ' jest', ' spry', 'tna', '.', ' Ale', ' ze', ' mną', ' nie', ' wygra', '!'] 14\n",
      "Ta wiewiórka jest sprytna. Ale ze mną nie wygra!\n"
     ]
    }
   ],
   "source": [
    "text = \"Ta wiewiórka jest sprytna. Ale ze mną nie wygra!\"\n",
    "ids = tokenizer(text, return_tensors='pt')['input_ids'][0]\n",
    "tokens = [tokenizer.decode(n) for n in ids]\n",
    "print(tokens, len(tokens))\n",
    "print(*tokens, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd20610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 50257])\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(text, return_tensors='pt')['input_ids'].to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids)\n",
    "print (output.logits.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eabd6aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n",
    "#out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n",
    "#out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n",
    "\n",
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "torch.gather(t, 0, torch.tensor([[0, 0], [1, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38cf13f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n",
      "tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor( [[1,2,3], [4,5,6]])\n",
    "for n in range(3):\n",
    "    print (a.unsqueeze(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90b66cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 50257]) torch.Size([1, 13, 1])\n",
      "torch.Size([1, 13, 1])\n"
     ]
    }
   ],
   "source": [
    "but_last_logits = output.logits[:, :-1, :]\n",
    "but_first_labels = input_ids[:, 1:]\n",
    "\n",
    "logp = F.log_softmax(but_last_logits, dim=-1)\n",
    "labels = but_first_labels.unsqueeze(2)\n",
    "print (logp.shape, labels.shape)\n",
    "\n",
    "gathered = torch.gather(logp, 2, labels)\n",
    "print (gathered.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb089abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    \n",
    "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logp_label\n",
    "    \n",
    "            \n",
    "def sentence_prob(sentence_txt):\n",
    "    input_ids = tokenizer(sentence_txt, return_tensors='pt')['input_ids'].to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids)\n",
    "        log_probs = log_probs_from_logits(output.logits[:, :-1, :], input_ids[:, 1:])\n",
    "        seq_log_probs = torch.sum(log_probs)\n",
    "    return seq_log_probs.cpu().numpy()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccff47f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ala -7.5044913\n",
      "Ala ma -11.766838\n",
      "Ala ma dwa -17.383055\n",
      "Ala ma dwa tłuste -28.23169\n",
      "Ala ma dwa tłuste koty -33.956753\n",
      "Ala ma dwa tłuste koty i -35.879913\n",
      "Ala ma dwa tłuste koty i ślicznego -45.49717\n",
      "Ala ma dwa tłuste koty i ślicznego kanarka -52.10604\n"
     ]
    }
   ],
   "source": [
    "words = 'Ala ma dwa tłuste koty i ślicznego kanarka'.split()\n",
    "\n",
    "for i in range(1,len(words)+1):\n",
    "    txt = ' '.join(words[:i])\n",
    "    print (txt, sentence_prob(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87e416d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kota -18.377638\n",
      "psa -20.369291\n",
      "słonia -25.758102\n",
      "nosorożca -27.199951\n",
      "krowę -22.857933\n",
      "konia -23.28639\n",
      "pereturbację -43.974747\n",
      "perturbację -32.565228\n"
     ]
    }
   ],
   "source": [
    "options = ['kota', 'psa', 'słonia', 'nosorożca', 'krowę', 'konia', 'pereturbację', 'perturbację']\n",
    "\n",
    "for opt in options:\n",
    "    print (opt, sentence_prob('Ala ma ' + opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81292b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kota -1.3126884187970842\n",
      "psa -1.4549493789672852\n",
      "słonia -1.8398644583565849\n",
      "nosorożca -1.9428536551339286\n",
      "krowę -1.6327095031738281\n",
      "konia -1.663313593183245\n",
      "pereturbację -3.1410533360072543\n",
      "perturbację -2.32608767918178\n"
     ]
    }
   ],
   "source": [
    "def normalized_sentence_prob(txt):\n",
    "    length = len(tokenizer(text, return_tensors='pt')['input_ids'][0])\n",
    "    return sentence_prob(txt) / length\n",
    "\n",
    "for opt in options:\n",
    "    print (opt, normalized_sentence_prob('Ala ma ' + opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac15804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kota -1.779935019356864\n",
      "psa -1.8222836085728236\n",
      "słonia -2.0925118582589284\n",
      "nosorożca -2.3730441502162387\n",
      "krowę -2.592665263584682\n",
      "konia -1.8791062491280692\n",
      "pereturbację -4.007100786481585\n",
      "perturbację -3.0986230032784596\n"
     ]
    }
   ],
   "source": [
    "for opt in options:\n",
    "    print (opt, normalized_sentence_prob('Ala nie ma ' + opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577c36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
