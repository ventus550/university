{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd5d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "\n",
    "model_name = 'flax-community/papuGaPT2'\n",
    "device = 'cuda'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccb512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ta', ' wie', 'wi', 'órka', ' jest', ' spry', 'tna', '.', ' Ale', ' ze', ' mną', ' nie', ' wygra', '!'] 14\n",
      "Ta wiewiórka jest sprytna. Ale ze mną nie wygra!\n"
     ]
    }
   ],
   "source": [
    "text = \"Ta wiewiórka jest sprytna. Ale ze mną nie wygra!\"\n",
    "ids = tokenizer(text, return_tensors='pt')['input_ids'][0]\n",
    "tokens = [tokenizer.decode(n) for n in ids]\n",
    "print(tokens, len(tokens))\n",
    "print(*tokens, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd20610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 50257])\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(text, return_tensors='pt')['input_ids'].to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids)\n",
    "print (output.logits.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13282dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-155.0427, -157.5392, -158.5438,  ..., -148.4494, -154.7137,\n",
       "          -150.1377],\n",
       "         [-108.9348, -111.8164, -112.2461,  ..., -101.2084,  -99.7926,\n",
       "           -99.7692],\n",
       "         [-107.2887, -106.1522, -107.3445,  ..., -104.5265,  -99.1293,\n",
       "           -96.8490],\n",
       "         ...,\n",
       "         [-157.6226, -164.6961, -163.0924,  ..., -152.9383, -153.5791,\n",
       "          -150.1659],\n",
       "         [-162.3093, -164.7065, -163.3595,  ..., -148.7633, -151.1780,\n",
       "          -149.8193],\n",
       "         [-173.4292, -179.4016, -179.4410,  ..., -155.1117, -155.1993,\n",
       "          -151.8837]]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ca52da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_next_token(sentence_token_ids, allowed_next_token_ids):\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = model(input_ids=sentence_token_ids)\n",
    "\t\tallowed_token_probs = F.softmax(output.logits.squeeze()[-1][allowed_next_token_ids]).cpu().numpy()\n",
    "\tprint(allowed_token_probs)\n",
    "\treturn np.random.choice(len(allowed_token_probs), p=allowed_token_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c998e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7039/897531570.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  allowed_token_probs = F.softmax(output.logits.squeeze()[-1][allowed_next_token_ids]).cpu().numpy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_next_token(tokenizer(\"Ala ma kota\", return_tensors='pt').input_ids.to(device), [91,    88,    74,  2986, 42202])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb089abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    return torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "\n",
    "def sentence_prob(sentence_txt):\n",
    "    input_ids = tokenizer(sentence_txt, return_tensors='pt')['input_ids'].to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids)\n",
    "        log_probs = log_probs_from_logits(output.logits[:, :-1, :], input_ids[:, 1:])\n",
    "        seq_log_probs = torch.sum(log_probs)\n",
    "    return seq_log_probs.cpu().numpy()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb7cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"wtf abcd\", return_tensors='pt')['input_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6229fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   91,    88,    74,  2986, 42202]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667789c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ab'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(2986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d73c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wtf abcd']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(id) for id in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'Ala ma dwa tłuste koty i ślicznego kanarka'.split()\n",
    "tords = [tokenizer(word).input_ids for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81398c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenTrie(dict):\n",
    "\tdef __init__(self, sequences=[]):\n",
    "\t\tself.terminal = False\n",
    "\t\tfor sequence in sequences:\n",
    "\t\t\tself.insert(sequence)\n",
    "\n",
    "\tdef insert(self, sequence):\n",
    "\t\tif not sequence:\n",
    "\t\t\tself.terminal = True\n",
    "\t\t\treturn self\n",
    "\n",
    "\t\tprefix, suffix = sequence[0], sequence[1:]\n",
    "\t\tif prefix in self:\n",
    "\t\t\tself[prefix].insert(suffix)\n",
    "\t\telse:\n",
    "\t\t\tself[prefix] = TokenTrie().insert(suffix)\n",
    "\t\treturn self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ed1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TokenTrie(tords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d6f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{37: {314: {}},\n",
       " 351: {},\n",
       " 14073: {},\n",
       " 5838: {666: {}},\n",
       " 315: {327: {}},\n",
       " 77: {},\n",
       " 642: {1054: {}},\n",
       " 303: {45538: {}}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154f4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
