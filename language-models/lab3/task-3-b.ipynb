{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf1dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 36786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.sso.sso_relationship.bias', 'cls.sso.sso_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from utils import load_model, load_review_data, configure_environment, logistic_regression, augment_data\n",
    "\n",
    "configure_environment()\n",
    "bert, bert_tokenizer, device = load_model(model_name=\"allegro/herbert-base-cased\")\n",
    "reviews_df = load_review_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95caf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation(txt):\n",
    "    input_ids = bert_tokenizer(txt, return_tensors='pt')['input_ids']\n",
    "    output = bert(input_ids=input_ids)\n",
    "    return output.last_hidden_state.detach().cpu().numpy()[0,0,:]\n",
    "\n",
    "def extract_features(df):\n",
    "\tdf = df.copy().join(df.text.apply(representation).apply(pd.Series).add_prefix('features.bert.'))\n",
    "\tdf.columns = pd.MultiIndex.from_tuples([col.split('.') for col in df.columns])\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128afedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(reviews_df, test_size=0.2, shuffle=True)\n",
    "train_features_df = extract_features(train_df)\n",
    "test_features_df = extract_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04944dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th colspan=\"19\" halign=\"left\">features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th colspan=\"19\" halign=\"left\">bert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupe≈Çnie inne podej≈õcie mia≈Ça Pani doktor na n...</td>\n",
       "      <td>-0.228186</td>\n",
       "      <td>0.106508</td>\n",
       "      <td>0.143653</td>\n",
       "      <td>0.100886</td>\n",
       "      <td>-0.583679</td>\n",
       "      <td>-0.448140</td>\n",
       "      <td>-0.050301</td>\n",
       "      <td>0.119306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090929</td>\n",
       "      <td>-0.336753</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.124735</td>\n",
       "      <td>0.266845</td>\n",
       "      <td>-0.022654</td>\n",
       "      <td>0.047777</td>\n",
       "      <td>0.132901</td>\n",
       "      <td>-0.025131</td>\n",
       "      <td>0.244655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>Poprawcie to.</td>\n",
       "      <td>-0.083961</td>\n",
       "      <td>-0.134343</td>\n",
       "      <td>0.200194</td>\n",
       "      <td>0.088947</td>\n",
       "      <td>-0.261745</td>\n",
       "      <td>0.336625</td>\n",
       "      <td>-0.156988</td>\n",
       "      <td>-0.372877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118508</td>\n",
       "      <td>-0.274321</td>\n",
       "      <td>-0.071802</td>\n",
       "      <td>0.471191</td>\n",
       "      <td>0.334924</td>\n",
       "      <td>-0.040434</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.185660</td>\n",
       "      <td>0.049927</td>\n",
       "      <td>0.074076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety mia≈Çam nieprzyjemno≈õƒá zetknƒÖƒá siƒô z n...</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.106501</td>\n",
       "      <td>-0.024241</td>\n",
       "      <td>0.028417</td>\n",
       "      <td>0.041316</td>\n",
       "      <td>0.191452</td>\n",
       "      <td>-0.029730</td>\n",
       "      <td>0.263827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.085410</td>\n",
       "      <td>0.080240</td>\n",
       "      <td>0.271734</td>\n",
       "      <td>0.384899</td>\n",
       "      <td>-0.104438</td>\n",
       "      <td>0.341161</td>\n",
       "      <td>-0.155862</td>\n",
       "      <td>0.273268</td>\n",
       "      <td>0.220608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True</td>\n",
       "      <td>Og√≥lnie polecam : ]</td>\n",
       "      <td>-0.452650</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>-0.036654</td>\n",
       "      <td>0.044954</td>\n",
       "      <td>-0.013617</td>\n",
       "      <td>0.378267</td>\n",
       "      <td>-0.142742</td>\n",
       "      <td>-0.131144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108367</td>\n",
       "      <td>0.364120</td>\n",
       "      <td>0.036408</td>\n",
       "      <td>-0.041373</td>\n",
       "      <td>0.354578</td>\n",
       "      <td>0.112237</td>\n",
       "      <td>0.489756</td>\n",
       "      <td>-0.057231</td>\n",
       "      <td>0.091037</td>\n",
       "      <td>0.545532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>True</td>\n",
       "      <td>Na zako≈Ñczenie leczenia rzeczowa, przyjacielsk...</td>\n",
       "      <td>0.034715</td>\n",
       "      <td>-0.198251</td>\n",
       "      <td>0.032767</td>\n",
       "      <td>-0.072684</td>\n",
       "      <td>-0.170697</td>\n",
       "      <td>0.444355</td>\n",
       "      <td>-0.032781</td>\n",
       "      <td>-0.273924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227748</td>\n",
       "      <td>0.206771</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.229205</td>\n",
       "      <td>0.276767</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>-0.120907</td>\n",
       "      <td>-0.530573</td>\n",
       "      <td>-0.074006</td>\n",
       "      <td>0.388413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>False</td>\n",
       "      <td>Wyda≈Çam ok 1300z≈Ç i na szczƒô≈õcie znalaz≈Çam inn...</td>\n",
       "      <td>-0.033959</td>\n",
       "      <td>0.197749</td>\n",
       "      <td>0.025394</td>\n",
       "      <td>-0.165185</td>\n",
       "      <td>0.178361</td>\n",
       "      <td>-0.091009</td>\n",
       "      <td>-0.075289</td>\n",
       "      <td>-0.277863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104002</td>\n",
       "      <td>-0.579222</td>\n",
       "      <td>0.105540</td>\n",
       "      <td>0.188452</td>\n",
       "      <td>0.335603</td>\n",
       "      <td>-0.143326</td>\n",
       "      <td>-0.336182</td>\n",
       "      <td>-0.226790</td>\n",
       "      <td>0.236538</td>\n",
       "      <td>-0.020417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>False</td>\n",
       "      <td>Dowiedzia≈Çem siƒô, ≈ºe je≈õli szczelina bƒôdzie mi...</td>\n",
       "      <td>-0.265117</td>\n",
       "      <td>0.099175</td>\n",
       "      <td>0.174028</td>\n",
       "      <td>-0.124155</td>\n",
       "      <td>0.046409</td>\n",
       "      <td>0.390323</td>\n",
       "      <td>-0.000872</td>\n",
       "      <td>-0.289533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>-0.050891</td>\n",
       "      <td>0.082499</td>\n",
       "      <td>0.277035</td>\n",
       "      <td>0.410913</td>\n",
       "      <td>-0.267114</td>\n",
       "      <td>-0.416551</td>\n",
       "      <td>-0.333245</td>\n",
       "      <td>0.116270</td>\n",
       "      <td>-0.105064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>False</td>\n",
       "      <td>Wino rozcieczone woda Jedzenie monotonne.</td>\n",
       "      <td>0.227190</td>\n",
       "      <td>0.083490</td>\n",
       "      <td>-0.156883</td>\n",
       "      <td>-0.065452</td>\n",
       "      <td>0.176190</td>\n",
       "      <td>0.157179</td>\n",
       "      <td>-0.175360</td>\n",
       "      <td>-0.171695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038006</td>\n",
       "      <td>0.348740</td>\n",
       "      <td>-0.010934</td>\n",
       "      <td>0.109342</td>\n",
       "      <td>0.058157</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.517455</td>\n",
       "      <td>-0.784506</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>-0.672104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Na moja uwagƒô, i≈º katar ostatnio trwa≈Ç d≈Çugo i...</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>0.063857</td>\n",
       "      <td>0.017946</td>\n",
       "      <td>-0.096863</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.331096</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>-0.232358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090488</td>\n",
       "      <td>0.050552</td>\n",
       "      <td>0.075482</td>\n",
       "      <td>0.193699</td>\n",
       "      <td>0.258856</td>\n",
       "      <td>-0.076792</td>\n",
       "      <td>0.039414</td>\n",
       "      <td>-0.574275</td>\n",
       "      <td>-0.037756</td>\n",
       "      <td>0.222950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obs≈Çuga w barze ( pozdrowieni...</td>\n",
       "      <td>0.221364</td>\n",
       "      <td>-0.029767</td>\n",
       "      <td>-0.108641</td>\n",
       "      <td>0.176262</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.067469</td>\n",
       "      <td>-0.090967</td>\n",
       "      <td>-0.078779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>-0.204341</td>\n",
       "      <td>0.049946</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>0.351829</td>\n",
       "      <td>-0.085705</td>\n",
       "      <td>0.089164</td>\n",
       "      <td>-0.852266</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>-0.039202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows √ó 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  features  \\\n",
       "       NaN                                                NaN      bert   \n",
       "       NaN                                                NaN         0   \n",
       "176   True  Zupe≈Çnie inne podej≈õcie mia≈Ça Pani doktor na n... -0.228186   \n",
       "256  False                                      Poprawcie to. -0.083961   \n",
       "366  False  Niestety mia≈Çam nieprzyjemno≈õƒá zetknƒÖƒá siƒô z n...  0.046734   \n",
       "95    True                                Og√≥lnie polecam : ] -0.452650   \n",
       "126   True  Na zako≈Ñczenie leczenia rzeczowa, przyjacielsk...  0.034715   \n",
       "..     ...                                                ...       ...   \n",
       "254  False  Wyda≈Çam ok 1300z≈Ç i na szczƒô≈õcie znalaz≈Çam inn... -0.033959   \n",
       "220  False  Dowiedzia≈Çem siƒô, ≈ºe je≈õli szczelina bƒôdzie mi... -0.265117   \n",
       "305  False          Wino rozcieczone woda Jedzenie monotonne.  0.227190   \n",
       "291  False  Na moja uwagƒô, i≈º katar ostatnio trwa≈Ç d≈Çugo i...  0.288273   \n",
       "365  False  Nieprofesjonalna obs≈Çuga w barze ( pozdrowieni...  0.221364   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "            1         2         3         4         5         6         7   \n",
       "176  0.106508  0.143653  0.100886 -0.583679 -0.448140 -0.050301  0.119306   \n",
       "256 -0.134343  0.200194  0.088947 -0.261745  0.336625 -0.156988 -0.372877   \n",
       "366  0.106501 -0.024241  0.028417  0.041316  0.191452 -0.029730  0.263827   \n",
       "95   0.011029 -0.036654  0.044954 -0.013617  0.378267 -0.142742 -0.131144   \n",
       "126 -0.198251  0.032767 -0.072684 -0.170697  0.444355 -0.032781 -0.273924   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "254  0.197749  0.025394 -0.165185  0.178361 -0.091009 -0.075289 -0.277863   \n",
       "220  0.099175  0.174028 -0.124155  0.046409  0.390323 -0.000872 -0.289533   \n",
       "305  0.083490 -0.156883 -0.065452  0.176190  0.157179 -0.175360 -0.171695   \n",
       "291  0.063857  0.017946 -0.096863  0.004496  0.331096  0.026300 -0.232358   \n",
       "365 -0.029767 -0.108641  0.176262  0.096322  0.067469 -0.090967 -0.078779   \n",
       "\n",
       "     ...                                                              \\\n",
       "     ...                                                               \n",
       "     ...       758       759       760       761       762       763   \n",
       "176  ... -0.090929 -0.336753  0.001660  0.124735  0.266845 -0.022654   \n",
       "256  ...  0.118508 -0.274321 -0.071802  0.471191  0.334924 -0.040434   \n",
       "366  ...  0.001247  0.085410  0.080240  0.271734  0.384899 -0.104438   \n",
       "95   ...  0.108367  0.364120  0.036408 -0.041373  0.354578  0.112237   \n",
       "126  ... -0.227748  0.206771  0.021383  0.229205  0.276767 -0.081775   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "254  ...  0.104002 -0.579222  0.105540  0.188452  0.335603 -0.143326   \n",
       "220  ...  0.097107 -0.050891  0.082499  0.277035  0.410913 -0.267114   \n",
       "305  ...  0.038006  0.348740 -0.010934  0.109342  0.058157  0.005926   \n",
       "291  ...  0.090488  0.050552  0.075482  0.193699  0.258856 -0.076792   \n",
       "365  ...  0.011472 -0.204341  0.049946  0.091792  0.351829 -0.085705   \n",
       "\n",
       "                                             \n",
       "                                             \n",
       "          764       765       766       767  \n",
       "176  0.047777  0.132901 -0.025131  0.244655  \n",
       "256  0.023334  0.185660  0.049927  0.074076  \n",
       "366  0.341161 -0.155862  0.273268  0.220608  \n",
       "95   0.489756 -0.057231  0.091037  0.545532  \n",
       "126 -0.120907 -0.530573 -0.074006  0.388413  \n",
       "..        ...       ...       ...       ...  \n",
       "254 -0.336182 -0.226790  0.236538 -0.020417  \n",
       "220 -0.416551 -0.333245  0.116270 -0.105064  \n",
       "305  0.517455 -0.784506  0.005514 -0.672104  \n",
       "291  0.039414 -0.574275 -0.037756  0.222950  \n",
       "365  0.089164 -0.852266  0.197400 -0.039202  \n",
       "\n",
       "[320 rows x 770 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d629d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 1.0, 'test': 0.775}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(\n",
    "\tx_train=train_features_df.features.values,\n",
    "\ty_train=train_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258d8b3",
   "metadata": {},
   "source": [
    "### Contextual Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a510f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 22:57:33.556543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-07 22:57:33.569589: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-07 22:57:33.573088: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-07 22:57:33.584162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-07 22:57:34.732638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "@dataclass\n",
    "class ContextualWordReplacement:\n",
    "    def contextual_word_replacement(self, text):\n",
    "        words = text.split()\n",
    "        word_to_replace_idx = random.randint(0, len(words)-1)\n",
    "        masked_text = \" \".join(words[:word_to_replace_idx] + [\"[MASK]\"] + words[word_to_replace_idx+1:])\n",
    "        predictions = fill_mask(masked_text)\n",
    "        new_word = predictions[0]['token_str']\n",
    "        words[word_to_replace_idx] = new_word\n",
    "        return \" \".join(words)\n",
    "        \n",
    "    def __call__(self, row: pd.Series) -> pd.Series:\n",
    "        row.text = self.contextual_word_replacement(row.text)\n",
    "        return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb91bd",
   "metadata": {},
   "source": [
    "#### K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b366676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupe≈Çnie inne podej≈õcie mia≈Ça Pani doktor na n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupe≈Çnie inne podej≈õcie mia≈Ça Pani doktor na n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>Poprawcie to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>. to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety mia≈Çam nieprzyjemno≈õƒá zetknƒÖƒá siƒô z n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>False</td>\n",
       "      <td>Wino rozcieczone woda Jedzenie .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Na moja uwagƒô, i≈º katar ostatnio trwa≈Ç d≈Çugo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Na moja uwagƒô, i≈º katar ostatnio trwa≈Ç d≈Çugo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obs≈Çuga w barze ( pozdrowieni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obs≈Çuga w barze ( pozdrowieni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "176   True  Zupe≈Çnie inne podej≈õcie mia≈Ça Pani doktor na n...\n",
       "176   True  Zupe≈Çnie inne podej≈õcie mia≈Ça Pani doktor na n...\n",
       "256  False                                      Poprawcie to.\n",
       "256  False                                              . to.\n",
       "366  False  Niestety mia≈Çam nieprzyjemno≈õƒá zetknƒÖƒá siƒô z n...\n",
       "..     ...                                                ...\n",
       "305  False                   Wino rozcieczone woda Jedzenie .\n",
       "291  False  Na moja uwagƒô, i≈º katar ostatnio trwa≈Ç d≈Çugo i...\n",
       "291  False  Na moja uwagƒô, i≈º katar ostatnio trwa≈Ç d≈Çugo i...\n",
       "365  False  Nieprofesjonalna obs≈Çuga w barze ( pozdrowieni...\n",
       "365  False  Nieprofesjonalna obs≈Çuga w barze ( pozdrowieni...\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_df = augment_data(train_df, augmentation=ContextualWordReplacement(), K=1)\n",
    "augmented_train_K1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64ab7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 0.996875, 'test': 0.7375}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_features_df = extract_features(augmented_train_K1_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K1_features_df.features.values,\n",
    "\ty_train=augmented_train_K1_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ef255",
   "metadata": {},
   "source": [
    "#### K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e7199c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 1.0, 'test': 0.675}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K3_df = augment_data(train_df, augmentation=ContextualWordReplacement(), K=3)\n",
    "augmented_train_K3_features_df = extract_features(augmented_train_K3_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K3_features_df.features.values,\n",
    "\ty_train=augmented_train_K3_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037793b1",
   "metadata": {},
   "source": [
    "### Back Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4afdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "@dataclass\n",
    "class BackTranslation:\n",
    "    language = \"en\"\n",
    "\n",
    "    def back_translation(self, text):\n",
    "        front = GoogleTranslator(source='pl', target=self.language)\n",
    "        back = GoogleTranslator(source=self.language, target='pl')\n",
    "        return back.translate(front.translate(text))\n",
    "        \n",
    "    def __call__(self, row: pd.Series) -> pd.Series:\n",
    "        row.text = self.back_translation(row.text)\n",
    "        return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd4a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.08 s, sys: 470 ms, total: 5.55 s\n",
      "Wall time: 9min 1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupe≈Çnie inne podej≈õcie mia≈Ça Pani doktor na n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupe≈Çnie inne podej≈õcie mia≈Ça lekarka pe≈ÇniƒÖca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>Poprawcie to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>Proszƒô to poprawiƒá.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety mia≈Çam nieprzyjemno≈õƒá zetknƒÖƒá siƒô z n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>False</td>\n",
       "      <td>Wino rozcie≈Ñczone wodƒÖ. Jedzenie monotonne.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Na moja uwagƒô, i≈º katar ostatnio trwa≈Ç d≈Çugo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Gdy zwr√≥ci≈Çam jej uwagƒô, ≈ºe przeziƒôbienie trwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obs≈Çuga w barze ( pozdrowieni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obs≈Çuga przy barze (pozdrowie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "176   True  Zupe≈Çnie inne podej≈õcie mia≈Ça Pani doktor na n...\n",
       "176   True  Zupe≈Çnie inne podej≈õcie mia≈Ça lekarka pe≈ÇniƒÖca...\n",
       "256  False                                      Poprawcie to.\n",
       "256  False                                Proszƒô to poprawiƒá.\n",
       "366  False  Niestety mia≈Çam nieprzyjemno≈õƒá zetknƒÖƒá siƒô z n...\n",
       "..     ...                                                ...\n",
       "305  False        Wino rozcie≈Ñczone wodƒÖ. Jedzenie monotonne.\n",
       "291  False  Na moja uwagƒô, i≈º katar ostatnio trwa≈Ç d≈Çugo i...\n",
       "291  False  Gdy zwr√≥ci≈Çam jej uwagƒô, ≈ºe przeziƒôbienie trwa...\n",
       "365  False  Nieprofesjonalna obs≈Çuga w barze ( pozdrowieni...\n",
       "365  False  Nieprofesjonalna obs≈Çuga przy barze (pozdrowie...\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "augmented_train_K1_df = augment_data(train_df, augmentation=BackTranslation(), K=1)\n",
    "augmented_train_K1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f54acb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 1.0, 'test': 0.75}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_features_df = extract_features(augmented_train_K1_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K1_features_df.features.values,\n",
    "\ty_train=augmented_train_K1_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fae5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
