{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf1dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 36786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.sso.sso_relationship.bias', 'cls.sso.sso_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from utils import load_model, load_review_data, configure_environment, logistic_regression, augment_data\n",
    "\n",
    "configure_environment()\n",
    "bert, bert_tokenizer, device = load_model(model_name=\"allegro/herbert-base-cased\")\n",
    "reviews_df = load_review_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95caf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation(txt):\n",
    "    input_ids = bert_tokenizer(txt, return_tensors='pt')['input_ids']\n",
    "    output = bert(input_ids=input_ids)\n",
    "    return output.last_hidden_state.detach().cpu().numpy()[0,0,:]\n",
    "\n",
    "def extract_features(df):\n",
    "\tdf = df.copy().join(df.text.apply(representation).apply(pd.Series).add_prefix('features.bert.'))\n",
    "\tdf.columns = pd.MultiIndex.from_tuples([col.split('.') for col in df.columns])\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128afedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(reviews_df, test_size=0.2, shuffle=True)\n",
    "train_features_df = extract_features(train_df)\n",
    "test_features_df = extract_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04944dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th colspan=\"19\" halign=\"left\">features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th colspan=\"19\" halign=\"left\">bert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupełnie inne podejście miała Pani doktor na n...</td>\n",
       "      <td>-0.228186</td>\n",
       "      <td>0.106508</td>\n",
       "      <td>0.143653</td>\n",
       "      <td>0.100886</td>\n",
       "      <td>-0.583679</td>\n",
       "      <td>-0.448140</td>\n",
       "      <td>-0.050301</td>\n",
       "      <td>0.119306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090929</td>\n",
       "      <td>-0.336753</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.124735</td>\n",
       "      <td>0.266845</td>\n",
       "      <td>-0.022654</td>\n",
       "      <td>0.047777</td>\n",
       "      <td>0.132901</td>\n",
       "      <td>-0.025131</td>\n",
       "      <td>0.244655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>Poprawcie to.</td>\n",
       "      <td>-0.083961</td>\n",
       "      <td>-0.134343</td>\n",
       "      <td>0.200194</td>\n",
       "      <td>0.088947</td>\n",
       "      <td>-0.261745</td>\n",
       "      <td>0.336625</td>\n",
       "      <td>-0.156988</td>\n",
       "      <td>-0.372877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118508</td>\n",
       "      <td>-0.274321</td>\n",
       "      <td>-0.071802</td>\n",
       "      <td>0.471191</td>\n",
       "      <td>0.334924</td>\n",
       "      <td>-0.040434</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.185660</td>\n",
       "      <td>0.049927</td>\n",
       "      <td>0.074076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety miałam nieprzyjemność zetknąć się z n...</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.106501</td>\n",
       "      <td>-0.024241</td>\n",
       "      <td>0.028417</td>\n",
       "      <td>0.041316</td>\n",
       "      <td>0.191452</td>\n",
       "      <td>-0.029730</td>\n",
       "      <td>0.263827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.085410</td>\n",
       "      <td>0.080240</td>\n",
       "      <td>0.271734</td>\n",
       "      <td>0.384899</td>\n",
       "      <td>-0.104438</td>\n",
       "      <td>0.341161</td>\n",
       "      <td>-0.155862</td>\n",
       "      <td>0.273268</td>\n",
       "      <td>0.220608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True</td>\n",
       "      <td>Ogólnie polecam : ]</td>\n",
       "      <td>-0.452650</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>-0.036654</td>\n",
       "      <td>0.044954</td>\n",
       "      <td>-0.013617</td>\n",
       "      <td>0.378267</td>\n",
       "      <td>-0.142742</td>\n",
       "      <td>-0.131144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108367</td>\n",
       "      <td>0.364120</td>\n",
       "      <td>0.036408</td>\n",
       "      <td>-0.041373</td>\n",
       "      <td>0.354578</td>\n",
       "      <td>0.112237</td>\n",
       "      <td>0.489756</td>\n",
       "      <td>-0.057231</td>\n",
       "      <td>0.091037</td>\n",
       "      <td>0.545532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>True</td>\n",
       "      <td>Na zakończenie leczenia rzeczowa, przyjacielsk...</td>\n",
       "      <td>0.034715</td>\n",
       "      <td>-0.198251</td>\n",
       "      <td>0.032767</td>\n",
       "      <td>-0.072684</td>\n",
       "      <td>-0.170697</td>\n",
       "      <td>0.444355</td>\n",
       "      <td>-0.032781</td>\n",
       "      <td>-0.273924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227748</td>\n",
       "      <td>0.206771</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.229205</td>\n",
       "      <td>0.276767</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>-0.120907</td>\n",
       "      <td>-0.530573</td>\n",
       "      <td>-0.074006</td>\n",
       "      <td>0.388413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>False</td>\n",
       "      <td>Wydałam ok 1300zł i na szczęście znalazłam inn...</td>\n",
       "      <td>-0.033959</td>\n",
       "      <td>0.197749</td>\n",
       "      <td>0.025394</td>\n",
       "      <td>-0.165185</td>\n",
       "      <td>0.178361</td>\n",
       "      <td>-0.091009</td>\n",
       "      <td>-0.075289</td>\n",
       "      <td>-0.277863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104002</td>\n",
       "      <td>-0.579222</td>\n",
       "      <td>0.105540</td>\n",
       "      <td>0.188452</td>\n",
       "      <td>0.335603</td>\n",
       "      <td>-0.143326</td>\n",
       "      <td>-0.336182</td>\n",
       "      <td>-0.226790</td>\n",
       "      <td>0.236538</td>\n",
       "      <td>-0.020417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>False</td>\n",
       "      <td>Dowiedziałem się, że jeśli szczelina będzie mi...</td>\n",
       "      <td>-0.265117</td>\n",
       "      <td>0.099175</td>\n",
       "      <td>0.174028</td>\n",
       "      <td>-0.124155</td>\n",
       "      <td>0.046409</td>\n",
       "      <td>0.390323</td>\n",
       "      <td>-0.000872</td>\n",
       "      <td>-0.289533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>-0.050891</td>\n",
       "      <td>0.082499</td>\n",
       "      <td>0.277035</td>\n",
       "      <td>0.410913</td>\n",
       "      <td>-0.267114</td>\n",
       "      <td>-0.416551</td>\n",
       "      <td>-0.333245</td>\n",
       "      <td>0.116270</td>\n",
       "      <td>-0.105064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>False</td>\n",
       "      <td>Wino rozcieczone woda Jedzenie monotonne.</td>\n",
       "      <td>0.227190</td>\n",
       "      <td>0.083490</td>\n",
       "      <td>-0.156883</td>\n",
       "      <td>-0.065452</td>\n",
       "      <td>0.176190</td>\n",
       "      <td>0.157179</td>\n",
       "      <td>-0.175360</td>\n",
       "      <td>-0.171695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038006</td>\n",
       "      <td>0.348740</td>\n",
       "      <td>-0.010934</td>\n",
       "      <td>0.109342</td>\n",
       "      <td>0.058157</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.517455</td>\n",
       "      <td>-0.784506</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>-0.672104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Na moja uwagę, iż katar ostatnio trwał długo i...</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>0.063857</td>\n",
       "      <td>0.017946</td>\n",
       "      <td>-0.096863</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.331096</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>-0.232358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090488</td>\n",
       "      <td>0.050552</td>\n",
       "      <td>0.075482</td>\n",
       "      <td>0.193699</td>\n",
       "      <td>0.258856</td>\n",
       "      <td>-0.076792</td>\n",
       "      <td>0.039414</td>\n",
       "      <td>-0.574275</td>\n",
       "      <td>-0.037756</td>\n",
       "      <td>0.222950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obsługa w barze ( pozdrowieni...</td>\n",
       "      <td>0.221364</td>\n",
       "      <td>-0.029767</td>\n",
       "      <td>-0.108641</td>\n",
       "      <td>0.176262</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.067469</td>\n",
       "      <td>-0.090967</td>\n",
       "      <td>-0.078779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>-0.204341</td>\n",
       "      <td>0.049946</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>0.351829</td>\n",
       "      <td>-0.085705</td>\n",
       "      <td>0.089164</td>\n",
       "      <td>-0.852266</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>-0.039202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  features  \\\n",
       "       NaN                                                NaN      bert   \n",
       "       NaN                                                NaN         0   \n",
       "176   True  Zupełnie inne podejście miała Pani doktor na n... -0.228186   \n",
       "256  False                                      Poprawcie to. -0.083961   \n",
       "366  False  Niestety miałam nieprzyjemność zetknąć się z n...  0.046734   \n",
       "95    True                                Ogólnie polecam : ] -0.452650   \n",
       "126   True  Na zakończenie leczenia rzeczowa, przyjacielsk...  0.034715   \n",
       "..     ...                                                ...       ...   \n",
       "254  False  Wydałam ok 1300zł i na szczęście znalazłam inn... -0.033959   \n",
       "220  False  Dowiedziałem się, że jeśli szczelina będzie mi... -0.265117   \n",
       "305  False          Wino rozcieczone woda Jedzenie monotonne.  0.227190   \n",
       "291  False  Na moja uwagę, iż katar ostatnio trwał długo i...  0.288273   \n",
       "365  False  Nieprofesjonalna obsługa w barze ( pozdrowieni...  0.221364   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "            1         2         3         4         5         6         7   \n",
       "176  0.106508  0.143653  0.100886 -0.583679 -0.448140 -0.050301  0.119306   \n",
       "256 -0.134343  0.200194  0.088947 -0.261745  0.336625 -0.156988 -0.372877   \n",
       "366  0.106501 -0.024241  0.028417  0.041316  0.191452 -0.029730  0.263827   \n",
       "95   0.011029 -0.036654  0.044954 -0.013617  0.378267 -0.142742 -0.131144   \n",
       "126 -0.198251  0.032767 -0.072684 -0.170697  0.444355 -0.032781 -0.273924   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "254  0.197749  0.025394 -0.165185  0.178361 -0.091009 -0.075289 -0.277863   \n",
       "220  0.099175  0.174028 -0.124155  0.046409  0.390323 -0.000872 -0.289533   \n",
       "305  0.083490 -0.156883 -0.065452  0.176190  0.157179 -0.175360 -0.171695   \n",
       "291  0.063857  0.017946 -0.096863  0.004496  0.331096  0.026300 -0.232358   \n",
       "365 -0.029767 -0.108641  0.176262  0.096322  0.067469 -0.090967 -0.078779   \n",
       "\n",
       "     ...                                                              \\\n",
       "     ...                                                               \n",
       "     ...       758       759       760       761       762       763   \n",
       "176  ... -0.090929 -0.336753  0.001660  0.124735  0.266845 -0.022654   \n",
       "256  ...  0.118508 -0.274321 -0.071802  0.471191  0.334924 -0.040434   \n",
       "366  ...  0.001247  0.085410  0.080240  0.271734  0.384899 -0.104438   \n",
       "95   ...  0.108367  0.364120  0.036408 -0.041373  0.354578  0.112237   \n",
       "126  ... -0.227748  0.206771  0.021383  0.229205  0.276767 -0.081775   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "254  ...  0.104002 -0.579222  0.105540  0.188452  0.335603 -0.143326   \n",
       "220  ...  0.097107 -0.050891  0.082499  0.277035  0.410913 -0.267114   \n",
       "305  ...  0.038006  0.348740 -0.010934  0.109342  0.058157  0.005926   \n",
       "291  ...  0.090488  0.050552  0.075482  0.193699  0.258856 -0.076792   \n",
       "365  ...  0.011472 -0.204341  0.049946  0.091792  0.351829 -0.085705   \n",
       "\n",
       "                                             \n",
       "                                             \n",
       "          764       765       766       767  \n",
       "176  0.047777  0.132901 -0.025131  0.244655  \n",
       "256  0.023334  0.185660  0.049927  0.074076  \n",
       "366  0.341161 -0.155862  0.273268  0.220608  \n",
       "95   0.489756 -0.057231  0.091037  0.545532  \n",
       "126 -0.120907 -0.530573 -0.074006  0.388413  \n",
       "..        ...       ...       ...       ...  \n",
       "254 -0.336182 -0.226790  0.236538 -0.020417  \n",
       "220 -0.416551 -0.333245  0.116270 -0.105064  \n",
       "305  0.517455 -0.784506  0.005514 -0.672104  \n",
       "291  0.039414 -0.574275 -0.037756  0.222950  \n",
       "365  0.089164 -0.852266  0.197400 -0.039202  \n",
       "\n",
       "[320 rows x 770 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d629d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 1.0, 'test': 0.775}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(\n",
    "\tx_train=train_features_df.features.values,\n",
    "\ty_train=train_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258d8b3",
   "metadata": {},
   "source": [
    "### Contextual Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a510f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 22:57:33.556543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-07 22:57:33.569589: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-07 22:57:33.573088: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-07 22:57:33.584162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-07 22:57:34.732638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "@dataclass\n",
    "class ContextualWordReplacement:\n",
    "    def contextual_word_replacement(self, text):\n",
    "        words = text.split()\n",
    "        word_to_replace_idx = random.randint(0, len(words)-1)\n",
    "        masked_text = \" \".join(words[:word_to_replace_idx] + [\"[MASK]\"] + words[word_to_replace_idx+1:])\n",
    "        predictions = fill_mask(masked_text)\n",
    "        new_word = predictions[0]['token_str']\n",
    "        words[word_to_replace_idx] = new_word\n",
    "        return \" \".join(words)\n",
    "        \n",
    "    def __call__(self, row: pd.Series) -> pd.Series:\n",
    "        row.text = self.contextual_word_replacement(row.text)\n",
    "        return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb91bd",
   "metadata": {},
   "source": [
    "#### K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b366676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupełnie inne podejście miała Pani doktor na n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupełnie inne podejście miała Pani doktor na n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>Poprawcie to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>. to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety miałam nieprzyjemność zetknąć się z n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>False</td>\n",
       "      <td>Wino rozcieczone woda Jedzenie .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Na moja uwagę, iż katar ostatnio trwał długo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Na moja uwagę, iż katar ostatnio trwał długo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obsługa w barze ( pozdrowieni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obsługa w barze ( pozdrowieni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "176   True  Zupełnie inne podejście miała Pani doktor na n...\n",
       "176   True  Zupełnie inne podejście miała Pani doktor na n...\n",
       "256  False                                      Poprawcie to.\n",
       "256  False                                              . to.\n",
       "366  False  Niestety miałam nieprzyjemność zetknąć się z n...\n",
       "..     ...                                                ...\n",
       "305  False                   Wino rozcieczone woda Jedzenie .\n",
       "291  False  Na moja uwagę, iż katar ostatnio trwał długo i...\n",
       "291  False  Na moja uwagę, iż katar ostatnio trwał długo i...\n",
       "365  False  Nieprofesjonalna obsługa w barze ( pozdrowieni...\n",
       "365  False  Nieprofesjonalna obsługa w barze ( pozdrowieni...\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_df = augment_data(train_df, augmentation=ContextualWordReplacement(), K=1)\n",
    "augmented_train_K1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64ab7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 0.996875, 'test': 0.7375}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_features_df = extract_features(augmented_train_K1_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K1_features_df.features.values,\n",
    "\ty_train=augmented_train_K1_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ef255",
   "metadata": {},
   "source": [
    "#### K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e7199c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 1.0, 'test': 0.675}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K3_df = augment_data(train_df, augmentation=ContextualWordReplacement(), K=3)\n",
    "augmented_train_K3_features_df = extract_features(augmented_train_K3_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K3_features_df.features.values,\n",
    "\ty_train=augmented_train_K3_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037793b1",
   "metadata": {},
   "source": [
    "### Back Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4afdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "@dataclass\n",
    "class BackTranslation:\n",
    "    language = \"en\"\n",
    "\n",
    "    def back_translation(self, text):\n",
    "        front = GoogleTranslator(source='pl', target=self.language)\n",
    "        back = GoogleTranslator(source=self.language, target='pl')\n",
    "        return back.translate(front.translate(text))\n",
    "        \n",
    "    def __call__(self, row: pd.Series) -> pd.Series:\n",
    "        row.text = self.back_translation(row.text)\n",
    "        return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd4a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.08 s, sys: 470 ms, total: 5.55 s\n",
      "Wall time: 9min 1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupełnie inne podejście miała Pani doktor na n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>True</td>\n",
       "      <td>Zupełnie inne podejście miała lekarka pełniąca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>Poprawcie to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>False</td>\n",
       "      <td>Proszę to poprawić.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety miałam nieprzyjemność zetknąć się z n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>False</td>\n",
       "      <td>Wino rozcieńczone wodą. Jedzenie monotonne.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Na moja uwagę, iż katar ostatnio trwał długo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>False</td>\n",
       "      <td>Gdy zwróciłam jej uwagę, że przeziębienie trwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obsługa w barze ( pozdrowieni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>False</td>\n",
       "      <td>Nieprofesjonalna obsługa przy barze (pozdrowie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "176   True  Zupełnie inne podejście miała Pani doktor na n...\n",
       "176   True  Zupełnie inne podejście miała lekarka pełniąca...\n",
       "256  False                                      Poprawcie to.\n",
       "256  False                                Proszę to poprawić.\n",
       "366  False  Niestety miałam nieprzyjemność zetknąć się z n...\n",
       "..     ...                                                ...\n",
       "305  False        Wino rozcieńczone wodą. Jedzenie monotonne.\n",
       "291  False  Na moja uwagę, iż katar ostatnio trwał długo i...\n",
       "291  False  Gdy zwróciłam jej uwagę, że przeziębienie trwa...\n",
       "365  False  Nieprofesjonalna obsługa w barze ( pozdrowieni...\n",
       "365  False  Nieprofesjonalna obsługa przy barze (pozdrowie...\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "augmented_train_K1_df = augment_data(train_df, augmentation=BackTranslation(), K=1)\n",
    "augmented_train_K1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f54acb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 1.0, 'test': 0.75}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_features_df = extract_features(augmented_train_K1_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K1_features_df.features.values,\n",
    "\ty_train=augmented_train_K1_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fae5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
