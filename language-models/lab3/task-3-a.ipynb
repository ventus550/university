{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf1dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 51749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.sso.sso_relationship.bias', 'cls.sso.sso_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from utils import load_model, load_review_data, configure_environment, logistic_regression, augment_data\n",
    "\n",
    "configure_environment()\n",
    "bert, bert_tokenizer, device = load_model(model_name=\"allegro/herbert-base-cased\")\n",
    "reviews_df = load_review_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95caf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation(txt):\n",
    "    input_ids = bert_tokenizer(txt, return_tensors='pt')['input_ids']\n",
    "    output = bert(input_ids=input_ids)\n",
    "    return output.last_hidden_state.detach().cpu().numpy()[0,0,:]\n",
    "\n",
    "def extract_features(df):\n",
    "\tdf = df.copy().join(df.text.apply(representation).apply(pd.Series).add_prefix('features.bert.'))\n",
    "\tdf.columns = pd.MultiIndex.from_tuples([col.split('.') for col in df.columns])\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128afedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(reviews_df, test_size=0.2, shuffle=True)\n",
    "train_features_df = extract_features(train_df)\n",
    "test_features_df = extract_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04944dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th colspan=\"19\" halign=\"left\">features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th colspan=\"19\" halign=\"left\">bert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>Działał mi bardzo ładnie, nie krzaczył się jak...</td>\n",
       "      <td>-0.250587</td>\n",
       "      <td>0.044173</td>\n",
       "      <td>0.118709</td>\n",
       "      <td>-0.100504</td>\n",
       "      <td>-0.102707</td>\n",
       "      <td>0.191547</td>\n",
       "      <td>-0.151845</td>\n",
       "      <td>-0.021836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096086</td>\n",
       "      <td>0.132005</td>\n",
       "      <td>-0.145207</td>\n",
       "      <td>0.288063</td>\n",
       "      <td>0.490282</td>\n",
       "      <td>-0.244557</td>\n",
       "      <td>0.085787</td>\n",
       "      <td>0.105476</td>\n",
       "      <td>0.391839</td>\n",
       "      <td>-0.558862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>False</td>\n",
       "      <td>Badanie trwało dosłownie moment - dr nie zleci...</td>\n",
       "      <td>-0.016805</td>\n",
       "      <td>-0.081440</td>\n",
       "      <td>-0.128962</td>\n",
       "      <td>-0.088329</td>\n",
       "      <td>0.157753</td>\n",
       "      <td>-0.417212</td>\n",
       "      <td>-0.205676</td>\n",
       "      <td>0.286694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116096</td>\n",
       "      <td>-0.218194</td>\n",
       "      <td>0.193157</td>\n",
       "      <td>0.208422</td>\n",
       "      <td>0.171440</td>\n",
       "      <td>-0.022037</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.153495</td>\n",
       "      <td>0.202705</td>\n",
       "      <td>0.037559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>True</td>\n",
       "      <td>Jedzenie w porządku.</td>\n",
       "      <td>-0.006820</td>\n",
       "      <td>0.101888</td>\n",
       "      <td>0.068190</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>0.019013</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>-0.102092</td>\n",
       "      <td>-0.380311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189698</td>\n",
       "      <td>0.185457</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.328520</td>\n",
       "      <td>0.299032</td>\n",
       "      <td>-0.085792</td>\n",
       "      <td>0.366902</td>\n",
       "      <td>-0.392819</td>\n",
       "      <td>-0.074393</td>\n",
       "      <td>0.072027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>False</td>\n",
       "      <td>Hotel nie powinien mieć ich 5.</td>\n",
       "      <td>-0.303546</td>\n",
       "      <td>0.026752</td>\n",
       "      <td>-0.012962</td>\n",
       "      <td>0.091690</td>\n",
       "      <td>-0.090015</td>\n",
       "      <td>-0.206873</td>\n",
       "      <td>-0.112513</td>\n",
       "      <td>0.086325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188722</td>\n",
       "      <td>-0.029026</td>\n",
       "      <td>0.038694</td>\n",
       "      <td>0.351946</td>\n",
       "      <td>0.246647</td>\n",
       "      <td>-0.070808</td>\n",
       "      <td>0.175360</td>\n",
       "      <td>0.032608</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>0.487502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>True</td>\n",
       "      <td>Gdy się chce czegoś u niej nauczyć - nie ma pr...</td>\n",
       "      <td>-0.089130</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.075258</td>\n",
       "      <td>0.295325</td>\n",
       "      <td>-0.572678</td>\n",
       "      <td>0.337507</td>\n",
       "      <td>0.094997</td>\n",
       "      <td>0.325756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170109</td>\n",
       "      <td>-0.244512</td>\n",
       "      <td>-0.042971</td>\n",
       "      <td>0.043389</td>\n",
       "      <td>0.325687</td>\n",
       "      <td>-0.141715</td>\n",
       "      <td>0.124149</td>\n",
       "      <td>-0.277762</td>\n",
       "      <td>-0.142268</td>\n",
       "      <td>0.192734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>True</td>\n",
       "      <td>Polecam gorąco!</td>\n",
       "      <td>-0.207426</td>\n",
       "      <td>-0.170036</td>\n",
       "      <td>-0.033940</td>\n",
       "      <td>0.257174</td>\n",
       "      <td>-0.018600</td>\n",
       "      <td>0.456678</td>\n",
       "      <td>-0.199067</td>\n",
       "      <td>0.100050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032488</td>\n",
       "      <td>0.116933</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>0.180119</td>\n",
       "      <td>0.098833</td>\n",
       "      <td>0.139046</td>\n",
       "      <td>-0.238715</td>\n",
       "      <td>0.148369</td>\n",
       "      <td>-0.048894</td>\n",
       "      <td>0.753203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>False</td>\n",
       "      <td>Jedyny minus to bardzo wysokie ceny jak na Pol...</td>\n",
       "      <td>-0.316551</td>\n",
       "      <td>-0.028436</td>\n",
       "      <td>-0.057008</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>-0.106427</td>\n",
       "      <td>0.071419</td>\n",
       "      <td>-0.113765</td>\n",
       "      <td>0.704119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132339</td>\n",
       "      <td>0.131630</td>\n",
       "      <td>-0.077902</td>\n",
       "      <td>0.242636</td>\n",
       "      <td>0.183911</td>\n",
       "      <td>-0.331103</td>\n",
       "      <td>0.148920</td>\n",
       "      <td>-0.680917</td>\n",
       "      <td>0.067205</td>\n",
       "      <td>0.059378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>True</td>\n",
       "      <td>Obsługa bardzo miła, pokoje ładne i czyste.</td>\n",
       "      <td>0.274798</td>\n",
       "      <td>0.026573</td>\n",
       "      <td>0.125020</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>0.343656</td>\n",
       "      <td>-0.028196</td>\n",
       "      <td>-0.310885</td>\n",
       "      <td>-0.744858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>-0.145936</td>\n",
       "      <td>0.250979</td>\n",
       "      <td>0.109129</td>\n",
       "      <td>-0.181861</td>\n",
       "      <td>-0.032184</td>\n",
       "      <td>-0.619223</td>\n",
       "      <td>0.095814</td>\n",
       "      <td>0.403707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>True</td>\n",
       "      <td>Używam go do panasonica lumix lx7, aparat nies...</td>\n",
       "      <td>-0.195864</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>0.068848</td>\n",
       "      <td>0.221020</td>\n",
       "      <td>-0.086630</td>\n",
       "      <td>0.287352</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.294634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>-0.323337</td>\n",
       "      <td>-0.012109</td>\n",
       "      <td>0.190511</td>\n",
       "      <td>0.277214</td>\n",
       "      <td>-0.298410</td>\n",
       "      <td>0.181176</td>\n",
       "      <td>-0.327683</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>-0.107572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety ale trąbi tu chór rozanielonych użytk...</td>\n",
       "      <td>0.027187</td>\n",
       "      <td>0.029354</td>\n",
       "      <td>-0.102934</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>-0.196491</td>\n",
       "      <td>0.153411</td>\n",
       "      <td>-0.169746</td>\n",
       "      <td>0.107803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>-0.147384</td>\n",
       "      <td>0.031695</td>\n",
       "      <td>0.375154</td>\n",
       "      <td>0.080390</td>\n",
       "      <td>0.027684</td>\n",
       "      <td>-0.453851</td>\n",
       "      <td>0.269439</td>\n",
       "      <td>0.068065</td>\n",
       "      <td>0.054675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  features  \\\n",
       "       NaN                                                NaN      bert   \n",
       "       NaN                                                NaN         0   \n",
       "35    True  Działał mi bardzo ładnie, nie krzaczył się jak... -0.250587   \n",
       "386  False  Badanie trwało dosłownie moment - dr nie zleci... -0.016805   \n",
       "90    True                               Jedzenie w porządku. -0.006820   \n",
       "231  False                     Hotel nie powinien mieć ich 5. -0.303546   \n",
       "177   True  Gdy się chce czegoś u niej nauczyć - nie ma pr... -0.089130   \n",
       "..     ...                                                ...       ...   \n",
       "185   True                                    Polecam gorąco! -0.207426   \n",
       "396  False  Jedyny minus to bardzo wysokie ceny jak na Pol... -0.316551   \n",
       "194   True        Obsługa bardzo miła, pokoje ładne i czyste.  0.274798   \n",
       "48    True  Używam go do panasonica lumix lx7, aparat nies... -0.195864   \n",
       "215  False  Niestety ale trąbi tu chór rozanielonych użytk...  0.027187   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "            1         2         3         4         5         6         7   \n",
       "35   0.044173  0.118709 -0.100504 -0.102707  0.191547 -0.151845 -0.021836   \n",
       "386 -0.081440 -0.128962 -0.088329  0.157753 -0.417212 -0.205676  0.286694   \n",
       "90   0.101888  0.068190  0.186785  0.019013  0.020581 -0.102092 -0.380311   \n",
       "231  0.026752 -0.012962  0.091690 -0.090015 -0.206873 -0.112513  0.086325   \n",
       "177  0.024326  0.075258  0.295325 -0.572678  0.337507  0.094997  0.325756   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "185 -0.170036 -0.033940  0.257174 -0.018600  0.456678 -0.199067  0.100050   \n",
       "396 -0.028436 -0.057008  0.002780 -0.106427  0.071419 -0.113765  0.704119   \n",
       "194  0.026573  0.125020  0.033270  0.343656 -0.028196 -0.310885 -0.744858   \n",
       "48   0.010850  0.068848  0.221020 -0.086630  0.287352  0.023075  0.294634   \n",
       "215  0.029354 -0.102934  0.063569 -0.196491  0.153411 -0.169746  0.107803   \n",
       "\n",
       "     ...                                                              \\\n",
       "     ...                                                               \n",
       "     ...       758       759       760       761       762       763   \n",
       "35   ...  0.096086  0.132005 -0.145207  0.288063  0.490282 -0.244557   \n",
       "386  ...  0.116096 -0.218194  0.193157  0.208422  0.171440 -0.022037   \n",
       "90   ...  0.189698  0.185457  0.002853  0.328520  0.299032 -0.085792   \n",
       "231  ... -0.188722 -0.029026  0.038694  0.351946  0.246647 -0.070808   \n",
       "177  ... -0.170109 -0.244512 -0.042971  0.043389  0.325687 -0.141715   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "185  ... -0.032488  0.116933  0.040579  0.180119  0.098833  0.139046   \n",
       "396  ...  0.132339  0.131630 -0.077902  0.242636  0.183911 -0.331103   \n",
       "194  ...  0.059801  0.102245 -0.145936  0.250979  0.109129 -0.181861   \n",
       "48   ...  0.020690 -0.323337 -0.012109  0.190511  0.277214 -0.298410   \n",
       "215  ...  0.007045 -0.147384  0.031695  0.375154  0.080390  0.027684   \n",
       "\n",
       "                                             \n",
       "                                             \n",
       "          764       765       766       767  \n",
       "35   0.085787  0.105476  0.391839 -0.558862  \n",
       "386  0.489000  0.153495  0.202705  0.037559  \n",
       "90   0.366902 -0.392819 -0.074393  0.072027  \n",
       "231  0.175360  0.032608 -0.004586  0.487502  \n",
       "177  0.124149 -0.277762 -0.142268  0.192734  \n",
       "..        ...       ...       ...       ...  \n",
       "185 -0.238715  0.148369 -0.048894  0.753203  \n",
       "396  0.148920 -0.680917  0.067205  0.059378  \n",
       "194 -0.032184 -0.619223  0.095814  0.403707  \n",
       "48   0.181176 -0.327683  0.009478 -0.107572  \n",
       "215 -0.453851  0.269439  0.068065  0.054675  \n",
       "\n",
       "[320 rows x 770 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d629d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.990625, 'test': 0.775}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(\n",
    "\tx_train=train_features_df.features.values,\n",
    "\ty_train=train_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258d8b3",
   "metadata": {},
   "source": [
    "### Capitalization augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd02b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RandomCapitilization:\n",
    "    max_capitalization=0.3\n",
    "    min_words=2\n",
    "    def random_capitalize(self, text):\n",
    "        words = text.split()\n",
    "        num_words_to_capitalize = max(1, int(len(words) * self.max_capitalization))\n",
    "        indices_to_capitalize = random.sample(range(len(words)), min(num_words_to_capitalize, self.min_words))\n",
    "        \n",
    "        for i in indices_to_capitalize:\n",
    "            words[i] = words[i].upper()\n",
    "        \n",
    "        return \" \".join(words)\n",
    "    \n",
    "    def __call__(self, row: pd.Series) -> pd.Series:\n",
    "        row.text = self.random_capitalize(row.text)\n",
    "        return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff6e939",
   "metadata": {},
   "source": [
    "#### K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a96e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>Działał mi bardzo ładnie, nie krzaczył się jak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>DZIAŁAŁ mi bardzo ładnie, nie krzaczył SIĘ jak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>Działał MI bardzo ładnie, nie krzaczył się jak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>Działał MI bardzo ładnie, nie krzaczył się jak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>False</td>\n",
       "      <td>Badanie trwało dosłownie moment - dr nie zleci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>True</td>\n",
       "      <td>UŻYWAM go do panasonica lumix lx7, APARAT nies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety ale trąbi tu chór rozanielonych użytk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>False</td>\n",
       "      <td>NIESTETY ale trąbi tu chór rozanielonych UŻYTK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety ale TRĄBI tu chór rozanielonych użytk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety ale trąbi tu chór rozanielonych użytk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "35    True  Działał mi bardzo ładnie, nie krzaczył się jak...\n",
       "35    True  DZIAŁAŁ mi bardzo ładnie, nie krzaczył SIĘ jak...\n",
       "35    True  Działał MI bardzo ładnie, nie krzaczył się jak...\n",
       "35    True  Działał MI bardzo ładnie, nie krzaczył się jak...\n",
       "386  False  Badanie trwało dosłownie moment - dr nie zleci...\n",
       "..     ...                                                ...\n",
       "48    True  UŻYWAM go do panasonica lumix lx7, APARAT nies...\n",
       "215  False  Niestety ale trąbi tu chór rozanielonych użytk...\n",
       "215  False  NIESTETY ale trąbi tu chór rozanielonych UŻYTK...\n",
       "215  False  Niestety ale TRĄBI tu chór rozanielonych użytk...\n",
       "215  False  Niestety ale trąbi tu chór rozanielonych użytk...\n",
       "\n",
       "[1280 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_df = augment_data(train_df, augmentation=RandomCapitilization(), K=3)\n",
    "augmented_train_K1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc08b595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 1.0, 'test': 0.8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_features_df = extract_features(augmented_train_K1_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K1_features_df.features.values,\n",
    "\ty_train=augmented_train_K1_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfc3a8",
   "metadata": {},
   "source": [
    "#### K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5cf3580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 1.0, 'test': 0.8375}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K3_df = augment_data(train_df, augmentation=RandomCapitilization(), K=3)\n",
    "augmented_train_K3_features_df = extract_features(augmented_train_K3_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K3_features_df.features.values,\n",
    "\ty_train=augmented_train_K3_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d3247",
   "metadata": {},
   "source": [
    "### Character swap augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a510f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RandomCharacterSwaps:\n",
    "    swaps = 0.1\n",
    "    def character_swap(self, text):\n",
    "        words = text.split()\n",
    "        word_idx = random.randint(0, len(words)-1)\n",
    "        word = words[word_idx]\n",
    "        \n",
    "        # Swap two random characters in the word\n",
    "        if len(word) > 1:\n",
    "            idx1, idx2 = random.sample(range(len(word)), 2)\n",
    "            word = list(word)\n",
    "            word[idx1], word[idx2] = word[idx2], word[idx1]\n",
    "            words[word_idx] = \"\".join(word)\n",
    "        \n",
    "        return \" \".join(words)\n",
    "        \n",
    "    def __call__(self, row: pd.Series) -> pd.Series:\n",
    "        swaps = int(self.swaps * len(row.text))\n",
    "        for _ in range(swaps):\n",
    "            row.text = self.character_swap(row.text)\n",
    "        return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb91bd",
   "metadata": {},
   "source": [
    "#### K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b366676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>Działał mi bardzo ładnie, nie krzaczył się jak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>Działał mi bardzo ładnie, nei krzaczył się jak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>False</td>\n",
       "      <td>Badanie trwało dosłownie moment - dr nie zleci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>False</td>\n",
       "      <td>Badanie trwało dosłownie moment - rd ine clize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>True</td>\n",
       "      <td>Jedzenie w porządku.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>True</td>\n",
       "      <td>Obsługa azrdbo miła, pokoje ładne i czyste.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>True</td>\n",
       "      <td>Używam go do panasonica lumix lx7, aparat nies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>True</td>\n",
       "      <td>Używam go do aanisonpca limux lx7, aparat nies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>False</td>\n",
       "      <td>Niestety ale trąbi tu chór rozanielonych użytk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>False</td>\n",
       "      <td>Neistety ael trąbi tu chór rozancelonyih użwtk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "35    True  Działał mi bardzo ładnie, nie krzaczył się jak...\n",
       "35    True  Działał mi bardzo ładnie, nei krzaczył się jak...\n",
       "386  False  Badanie trwało dosłownie moment - dr nie zleci...\n",
       "386  False  Badanie trwało dosłownie moment - rd ine clize...\n",
       "90    True                               Jedzenie w porządku.\n",
       "..     ...                                                ...\n",
       "194   True        Obsługa azrdbo miła, pokoje ładne i czyste.\n",
       "48    True  Używam go do panasonica lumix lx7, aparat nies...\n",
       "48    True  Używam go do aanisonpca limux lx7, aparat nies...\n",
       "215  False  Niestety ale trąbi tu chór rozanielonych użytk...\n",
       "215  False  Neistety ael trąbi tu chór rozancelonyih użwtk...\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_df = augment_data(train_df, augmentation=RandomCharacterSwaps(), K=1)\n",
    "augmented_train_K1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64ab7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 0.996875, 'test': 0.7875}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K1_features_df = extract_features(augmented_train_K1_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K1_features_df.features.values,\n",
    "\ty_train=augmented_train_K1_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ef255",
   "metadata": {},
   "source": [
    "#### K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e7199c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ventus/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 0.99140625, 'test': 0.8}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_K3_df = augment_data(train_df, augmentation=RandomCharacterSwaps(), K=3)\n",
    "augmented_train_K3_features_df = extract_features(augmented_train_K3_df)\n",
    "logistic_regression(\n",
    "\tx_train=augmented_train_K3_features_df.features.values,\n",
    "\ty_train=augmented_train_K3_features_df.label.values.squeeze(),\n",
    "\tx_test=test_features_df.features.values,\n",
    "\ty_test=test_features_df.label.values.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afdc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
